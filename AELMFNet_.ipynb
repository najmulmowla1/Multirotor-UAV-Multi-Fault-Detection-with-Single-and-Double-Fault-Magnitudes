{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtlnX3t-Rg_Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os\n",
        "import glob as gb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from zipfile import ZipFile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df_path = '/content/dataset.csv'\n",
        "df = pd.read_csv(df_path)\n"
      ],
      "metadata": {
        "id": "QkPWyqxef15E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the first few rows of the modified sheet\n",
        "print(f'First few rows of the modified sheet:')\n",
        "print(df.head())\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "Qn3yQgg8gB-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['t/s', 'p', 'q', 'r', 'mx', 'my', 'mz']\n",
        "X = df[features].values\n",
        "\n",
        "# Extract fault values (m1, m2, m3, m4) as targets\n",
        "targets = df[['m1', 'm2', 'm3', 'm4']].values"
      ],
      "metadata": {
        "id": "Nn7RptYUYpZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, targets, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f_nDSvgyZMXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data using Min-Max scaling (The minimum value of each feature becomes 0 and the maximum value becomes 1.)\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "u3fdUqyzZVh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the scaled values for inspection\n",
        "print(\"X_train_scaled:\\n\", X_train_scaled)\n",
        "print(\"\\nX_test_scaled:\\n\", X_test_scaled)"
      ],
      "metadata": {
        "id": "OrlueW4kZWN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Reshape the input data (converts each row into a unique id-variable) (In the new shape, the first dimension remains the number of samples,\n",
        "\n",
        "\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
      ],
      "metadata": {
        "id": "4jKKPA7sZkg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, RepeatVector, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import Huber\n",
        "\n",
        "# Define the input shape and latent dimension\n",
        "input_shape = (X_train_reshaped.shape[1], X_train_reshaped.shape[2])\n",
        "latent_dim = 3\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "# Encoder\n",
        "encoder = LSTM(100, activation='relu', return_sequences=True)(input_layer)\n",
        "encoder = LSTM(75, activation='relu', return_sequences=True)(encoder)\n",
        "encoder = LSTM(50, activation='relu', return_sequences=True)(encoder)\n",
        "encoder = LSTM(25, activation='relu', return_sequences=True)(encoder)\n",
        "encoder = LSTM(latent_dim, activation='relu')(encoder)\n",
        "\n",
        "# Decoder\n",
        "decoder = RepeatVector(X_train_reshaped.shape[1])(encoder)\n",
        "decoder = LSTM(25, activation='relu', return_sequences=True)(decoder)\n",
        "decoder = LSTM(50, activation='relu', return_sequences=True)(decoder)\n",
        "decoder = LSTM(75, activation='relu', return_sequences=True)(decoder)\n",
        "decoder = LSTM(100, activation='relu', return_sequences=True)(decoder)\n",
        "decoder = LSTM(X_train_reshaped.shape[2], activation='sigmoid', return_sequences=True)(decoder)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(input_layer, decoder)\n",
        "\n",
        "# Define custom loss function - Huber Loss\n",
        "def custom_huber_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(Huber()(y_true, y_pred))\n",
        "\n",
        "# Compile the model with the custom loss\n",
        "autoencoder.compile(optimizer='adam', loss=custom_huber_loss)\n",
        "\n",
        "# Print the summary\n",
        "autoencoder.summary()\n"
      ],
      "metadata": {
        "id": "pSXIOQVkZwSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the autoencoder and monitor metrics\n",
        "history = autoencoder.fit(X_train_reshaped, [X_train_reshaped, X_train_reshaped], epochs=100, batch_size=32, validation_split=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "zM4_2J2wAzIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "loss_value = autoencoder.evaluate(X_test_reshaped, [X_test_reshaped, X_test_reshaped])\n",
        "\n",
        "# Print the total loss value\n",
        "print(\"Total Loss:\", loss_value)\n"
      ],
      "metadata": {
        "id": "WSzQ7hp0hebY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict the reconstructed outputs\n",
        "reconstructed_outputs = autoencoder.predict(X_test_reshaped)\n",
        "\n",
        "# Choose a sample index\n",
        "sample_index = 0\n",
        "\n",
        "# Original input\n",
        "original_input = X_test_reshaped[sample_index]\n",
        "\n",
        "# Reconstructed output\n",
        "reconstructed_output = reconstructed_outputs[sample_index]\n",
        "\n",
        "# Set font\n",
        "plt.rcParams['font.family'] = 'Times New Roman'\n",
        "\n",
        "# Create a figure with higher DPI\n",
        "plt.figure(figsize=(12, 6), dpi=400)\n",
        "\n",
        "# Plot original input\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(original_input.flatten(), label='Original Input', color='blue')\n",
        "plt.title('Original Input', fontsize=16)\n",
        "plt.xlabel('Time', fontsize=14)\n",
        "plt.ylabel('Magnitude', fontsize=14)\n",
        "\n",
        "# Plot reconstructed output\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(reconstructed_output.flatten(), label='Reconstructed Output', color='red')\n",
        "plt.title('Reconstructed Output', fontsize=16)\n",
        "plt.xlabel('Time', fontsize=14)\n",
        "plt.ylabel('Magnitude', fontsize=14)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plt.savefig('reconstruction_plot.png', dpi=400)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1S4tOYrSCH2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the values of original input and reconstructed output\n",
        "print(\"Original Input Values:\", original_input.flatten())\n",
        "print(\"Reconstructed Output Values:\", reconstructed_output.flatten())\n"
      ],
      "metadata": {
        "id": "wimF2gpTCRZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define encoder model\n",
        "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
        "\n",
        "# Encode the input data to get the latent space representations\n",
        "latent_space_representation = encoder_model.predict(X_train_reshaped)\n"
      ],
      "metadata": {
        "id": "JBfPsitiCeZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Define journal colors\n",
        "tsne_color = '#D55E00'  # Orange color for t-SNE plot\n",
        "\n",
        "# Perform t-SNE to reduce the dimensionality of the latent space representations\n",
        "tsne = TSNE(n_components=2)\n",
        "latent_space_tsne = tsne.fit_transform(latent_space_representation)\n",
        "\n",
        "# Set font\n",
        "plt.rcParams['font.family'] = 'Times New Roman'\n",
        "\n",
        "# Plot the latent space representations\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(latent_space_tsne[:, 0], latent_space_tsne[:, 1], c=tsne_color, alpha=0.5)\n",
        "plt.title('Latent Space Visualization (t-SNE)', fontsize=18)\n",
        "plt.xlabel('t-SNE Dimension 1', fontsize=14)\n",
        "plt.ylabel('t-SNE Dimension 2', fontsize=14)\n",
        "plt.grid(False)  # Remove grid lines\n",
        "\n",
        "# Increase tick font size\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Save the plot with DPI 400\n",
        "plt.savefig('latent_space_tsne.png', dpi=400, bbox_inches='tight', transparent=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "d233D8ADCmAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the latent space representations\n",
        "print(\"Latent Space Representations:\")\n",
        "print(latent_space_representation)\n"
      ],
      "metadata": {
        "id": "eeU8aUigCzxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "\n",
        "# Define alternative colors\n",
        "training_color = '#DD8452'     # Lighter orange color for training loss\n",
        "validation_color = '#8172B0'   # Light purple color for validation loss\n",
        "\n",
        "# Collect the loss values from the History object\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Set font\n",
        "plt.rcParams['font.family'] = 'Times New Roman'\n",
        "\n",
        "# Create figure and axis objects\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Plot the training and validation loss values\n",
        "hist, bins = np.histogram(loss, bins=20)\n",
        "x = (bins[:-1] + bins[1:]) / 2\n",
        "ax.bar(x, hist, zs=0, zdir='y', width=0.7, color=training_color, alpha=0.8, label='Training Loss')\n",
        "\n",
        "hist, bins = np.histogram(val_loss, bins=20)\n",
        "x = (bins[:-1] + bins[1:]) / 2\n",
        "ax.bar(x, hist, zs=1, zdir='y', width=0.7, color=validation_color, alpha=0.8, label='Validation Loss')\n",
        "\n",
        "# Set plot title and labels\n",
        "ax.set_title('Histogram of Loss Values with Huber Loss Function', fontsize=18, pad=20)\n",
        "ax.set_xlabel('Loss', fontsize=14, labelpad=15)\n",
        "ax.set_ylabel('Frequency', fontsize=14, labelpad=15)\n",
        "ax.set_zlabel('Count', fontsize=14, labelpad=15)\n",
        "\n",
        "# Add legend\n",
        "ax.legend(fontsize=14)\n",
        "\n",
        "# Increase tick font size\n",
        "ax.tick_params(axis='both', which='major', labelsize=12, pad=8)\n",
        "\n",
        "# Remove grid lines\n",
        "ax.grid(False)\n",
        "\n",
        "# Set transparent background\n",
        "ax.patch.set_alpha(0)\n",
        "\n",
        "# Save the plot with DPI 400\n",
        "plt.savefig('loss_histogram_3d.png', dpi=400, bbox_inches='tight', transparent=True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wk6gplN3C1cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first few loss values\n",
        "print(\"Training Loss Values:\", loss[:5])\n",
        "print(\"Validation Loss Values:\", val_loss[:5])\n",
        "\n",
        "# Print the mean and standard deviation of the loss values\n",
        "print(\"Mean Training Loss:\", np.mean(loss))\n",
        "print(\"Mean Validation Loss:\", np.mean(val_loss))\n",
        "print(\"Standard Deviation of Training Loss:\", np.std(loss))\n",
        "print(\"Standard Deviation of Validation Loss:\", np.std(val_loss))\n"
      ],
      "metadata": {
        "id": "2Uviz8bEDATS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}